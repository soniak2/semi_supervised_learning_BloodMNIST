25%
              precision    recall  f1-score   support

           0       0.90      0.81      0.86       244
           1       0.98      0.99      0.99       624
           2       0.97      0.91      0.94       311
           3       0.81      0.86      0.83       579
           4       0.90      0.91      0.91       243
           5       0.84      0.82      0.83       284
           6       0.96      0.97      0.97       666
           7       1.00      1.00      1.00       470

    accuracy                           0.93      3421
   macro avg       0.92      0.91      0.91      3421
weighted avg       0.93      0.93      0.93      3421

[[198   3   1  26   6  10   0   0]
 [  1 620   0   3   0   0   0   0]
 [  4   2 282  14   4   2   3   0]
 [ 14   5   1 497  11  30  21   0]
 [  0   0   5  14 222   2   0   0]
 [  2   0   1  45   3 233   0   0]
 [  0   2   1  18   0   0 645   0]
 [  0   0   0   0   0   0   0 470]]


              precision    recall  f1-score   support

           0       0.76      0.86      0.81       244
           1       0.98      0.98      0.98       624
           2       0.94      0.90      0.92       311
           3       0.82      0.71      0.76       579
           4       0.83      0.97      0.89       243
           5       0.74      0.82      0.78       284
           6       0.97      0.94      0.96       666
           7       1.00      1.00      1.00       470

    accuracy                           0.90      3421
   macro avg       0.88      0.90      0.89      3421
weighted avg       0.90      0.90      0.90      3421

[[210   1   1  10  11  11   0   0]
 [  1 612   0   5   2   3   1   0]
 [  7   1 281   9   8   0   3   2]
 [ 47   7  10 412  22  64  17   0]
 [  0   0   2   4 236   1   0   0]
 [ 10   0   0  35   7 232   0   0]
 [  0   3   6  26   0   2 629   0]
 [  0   0   0   0   0   0   0 470]]

==================================
10%
              precision    recall  f1-score   support

           0       0.65      0.77      0.70       244
           1       0.98      0.99      0.98       624
           2       0.93      0.90      0.92       311
           3       0.74      0.61      0.67       579
           4       0.79      0.93      0.85       243
           5       0.69      0.75      0.72       284
           6       0.95      0.95      0.95       666
           7       1.00      1.00      1.00       470

    accuracy                           0.87      3421
   macro avg       0.84      0.86      0.85      3421
weighted avg       0.87      0.87      0.87      3421

[[188   0   1  26  20   9   0   0]
 [  3 615   0   2   1   3   0   0]
 [  5   1 280  13   8   1   2   1]
 [ 82   7   8 353  20  77  32   0]
 [  0   0   3  11 226   3   0   0]
 [ 13   0   0  50   9 212   0   0]
 [  0   2   7  20   2   2 633   0]
 [  0   0   1   0   0   0   0 469]]

              precision    recall  f1-score   support

           0       0.67      0.80      0.73       244
           1       0.98      0.97      0.98       624
           2       0.92      0.91      0.91       311
           3       0.72      0.59      0.65       579
           4       0.80      0.93      0.86       243
           5       0.65      0.71      0.68       284
           6       0.95      0.95      0.95       666
           7       1.00      1.00      1.00       470

    accuracy                           0.86      3421
   macro avg       0.83      0.86      0.84      3421
weighted avg       0.86      0.86      0.86      3421

[[195   1   1  24  18   5   0   0]
 [  4 604   0  10   2   3   1   0]
 [  5   1 282  10   7   1   4   1]
 [ 72   6   8 342  23  98  30   0]
 [  2   0   4   9 226   2   0   0]
 [ 14   0   1  61   7 201   0   0]
 [  0   2  10  22   1   1 630   0]
 [  0   0   0   0   0   0   0 470]]

==================================
5% -> 0.8347
              precision    recall  f1-score   support

           0       1.00      0.17      0.29       244
           1       0.98      0.98      0.98       624
           2       0.96      0.78      0.87       311
           3       0.52      0.70      0.60       579
           4       0.91      0.62      0.74       243
           5       0.52      0.74      0.61       284
           6       0.94      0.94      0.94       666
           7       0.98      1.00      0.99       470

    accuracy                           0.81      3421
   macro avg       0.85      0.74      0.75      3421
weighted avg       0.85      0.81      0.80      3421

[[ 42   1   0 143  13  44   1   0]
 [  0 613   0   4   0   3   4   0]
 [  0   1 244  37   2   1  16  10]
 [  0  11   1 406   0 143  18   0]
 [  0   0   5  83 150   5   0   0]
 [  0   0   0  74   0 210   0   0]
 [  0   1   3  33   0   1 628   0]
 [  0   0   0   0   0   0   2 468]]

==================================
  5% - Test accuracy: 0.1754
 10% - Test accuracy: 0.7602
 25% - Test accuracy: 0.8339
 50% - Test accuracy: 0.9170
 75% - Test accuracy: 0.9446
100% - Test accuracy: 0.9538

==================================
sizes = [0.05, 0.1, 0.25, 0.5, 0.75, 1.0] (5 reps)
means:  [np.float64(0.2198830395936966), np.float64(0.7625730991363525), np.float64(0.8407017469406128), np.float64(0.9069005966186523), np.float64(0.9296686172485351), np.float64(0.9546331524848938)]
stds:  [np.float64(0.039593708018591446), np.float64(0.051461999118331006), np.float64(0.014578173082278009), np.float64(0.00503603423785939), np.float64(0.009993282786952117), np.float64(0.000651014537135622)]



Sample 0: [8.8102492e-03 9.7436768e-01 3.0496402e-03 9.5604490e-03 9.8956446e-04 1.5217875e-03 1.2609595e-03 4.3959817e-04]
Sample 1: [0.18578814 0.01493682 0.20717934 0.08726374 0.4290498  0.00967113 0.04677086 0.01934016]
Sample 2: [0.00729502 0.00179096 0.45448846 0.01943716 0.12185814 0.00090161 0.03691012 0.3573185 ]
Sample 3: [0.25022405 0.02925591 0.13643663 0.16672263 0.3131455  0.05118546 0.03541419 0.01761559]
Sample 4: [0.0127404  0.0027182  0.54963773 0.02791398 0.17859162 0.00122875 0.02738718 0.19978213]
Sample 5: [0.1340625  0.32841116 0.10910457 0.14058901 0.0919833  0.02621356 0.13501786 0.0346181 ]
Sample 6: [0.2813207  0.05666593 0.02429542 0.21268207 0.10169537 0.28832123 0.01796246 0.01705683]
Sample 7: [1.0156820e-03 4.6621580e-04 2.1574499e-01 9.1613159e-03 2.6603840e-02 4.0269500e-04 5.0673434e-03 7.4153781e-01] 
Sample 8: [0.21133693 0.09783354 0.04091443 0.23277566 0.08387131 0.21977918 0.07747834 0.03601056]
Sample 9: [0.08786118 0.06359662 0.18008497 0.16722809 0.0903016  0.03360861 0.29389855 0.08342037]
